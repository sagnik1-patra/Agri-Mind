{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0e9400-f0cd-4ece-ad6c-df17ddd2399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved accuracy graph -> C:\\Users\\sagni\\Downloads\\Agri Mind\\loss_mae.png\n",
      "[OK] Saved prediction heatmap -> C:\\Users\\sagni\\Downloads\\Agri Mind\\pred_vs_actual_hex.png\n",
      "[OK] Saved correlation heatmap -> C:\\Users\\sagni\\Downloads\\Agri Mind\\corr_heatmap.png\n",
      "[OK] Saved error pivot heatmap -> C:\\Users\\sagni\\Downloads\\Agri Mind\\error_heatmap.png\n",
      "[DONE] Plots saved in: C:\\Users\\sagni\\Downloads\\Agri Mind\n"
     ]
    }
   ],
   "source": [
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try seaborn for nicer heatmaps; fall back to matplotlib if unavailable.\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    _HAS_SEABORN = True\n",
    "except Exception:\n",
    "    _HAS_SEABORN = False\n",
    "\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ----------------------------\n",
    "# Paths (edit if needed)\n",
    "# ----------------------------\n",
    "BASE_DIR = r\"C:\\Users\\sagni\\Downloads\\Agri Mind\"\n",
    "ARCHIVE  = os.path.join(BASE_DIR, \"archive\")\n",
    "\n",
    "HISTCSV  = os.path.join(BASE_DIR, \"neuro_history.csv\")\n",
    "PKL_PATH = os.path.join(BASE_DIR, \"neuro_preprocess.pkl\")\n",
    "H5_PATH  = os.path.join(BASE_DIR, \"neuro_model.h5\")\n",
    "DATACSV  = os.path.join(ARCHIVE, \"yield_df.csv\")\n",
    "\n",
    "# If your target column is different, change here or auto-detect below.\n",
    "POSSIBLE_TARGETS = [\"hg/ha_yield\", \"yield\", \"Yield\", \"target\", \"y\"]\n",
    "\n",
    "# ----------------------------\n",
    "# Utils\n",
    "# ----------------------------\n",
    "def _ensure_dir(p):\n",
    "    os.makedirs(os.path.dirname(p), exist_ok=True)\n",
    "\n",
    "def _detect_target(df: pd.DataFrame) -> str:\n",
    "    for c in POSSIBLE_TARGETS:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    # fallback to last numeric col\n",
    "    nums = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not nums:\n",
    "        raise ValueError(\"No numeric columns available to choose a target.\")\n",
    "    return nums[-1]\n",
    "\n",
    "def _to_numpy(X):\n",
    "    return X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Accuracy Graph (Loss & MAE)\n",
    "# ----------------------------\n",
    "def plot_training_curves(history_csv: str, out_path: str):\n",
    "    if not os.path.exists(history_csv):\n",
    "        print(f\"[WARN] history CSV not found: {history_csv}\")\n",
    "        return\n",
    "    hist = pd.read_csv(history_csv)\n",
    "    # Expected columns: epoch, loss, val_loss, mae, val_mae (Keras CSVLogger)\n",
    "    plt.figure(figsize=(9,5))\n",
    "    if \"loss\" in hist.columns:\n",
    "        plt.plot(hist[\"loss\"], label=\"Train Loss\")\n",
    "    if \"val_loss\" in hist.columns:\n",
    "        plt.plot(hist[\"val_loss\"], label=\"Val Loss\")\n",
    "    if \"mae\" in hist.columns:\n",
    "        plt.plot(hist[\"mae\"], label=\"Train MAE\")\n",
    "    if \"val_mae\" in hist.columns:\n",
    "        plt.plot(hist[\"val_mae\"], label=\"Val MAE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Training Curves (Loss & MAE)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    _ensure_dir(out_path)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=160)\n",
    "    plt.close()\n",
    "    print(f\"[OK] Saved accuracy graph -> {out_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Predictions vs Actual (Hexbin heatmap)\n",
    "# ----------------------------\n",
    "def plot_pred_vs_actual_hex(preprocess_pkl: str, model_h5: str, data_csv: str, out_path: str):\n",
    "    if not (os.path.exists(preprocess_pkl) and os.path.exists(model_h5) and os.path.exists(data_csv)):\n",
    "        print(\"[WARN] Missing one of preprocess/model/data files; skipping pred-vs-actual plot.\")\n",
    "        return\n",
    "    bundle = joblib.load(preprocess_pkl)\n",
    "    pre = bundle[\"preprocess\"]\n",
    "    df = pd.read_csv(data_csv)\n",
    "    target = bundle.get(\"target_col\", None) or _detect_target(df)\n",
    "    df = df.dropna(subset=[target]).copy()\n",
    "\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target].astype(float).values\n",
    "    Xp = pre.transform(X)\n",
    "\n",
    "    # IMPORTANT: avoid recompiling/deserializing legacy 'mse' by disabling compile\n",
    "    model = keras.models.load_model(model_h5, compile=False)\n",
    "    yhat = model.predict(_to_numpy(Xp), verbose=0).ravel()\n",
    "\n",
    "    # Hexbin 2D histogram\n",
    "    plt.figure(figsize=(6.8,6))\n",
    "    hb = plt.hexbin(y, yhat, gridsize=50, mincnt=1)\n",
    "    plt.colorbar(hb, label='Count')\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    lim_min = np.nanmin([y.min(), yhat.min()])\n",
    "    lim_max = np.nanmax([y.max(), yhat.max()])\n",
    "    plt.plot([lim_min, lim_max], [lim_min, lim_max], ls=\"--\", lw=1, color=\"black\", label=\"Ideal\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Predicted vs Actual (Hexbin Heatmap)\")\n",
    "    plt.tight_layout()\n",
    "    _ensure_dir(out_path)\n",
    "    plt.savefig(out_path, dpi=160)\n",
    "    plt.close()\n",
    "    print(f\"[OK] Saved prediction heatmap -> {out_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Correlation Heatmap (numeric features)\n",
    "# ----------------------------\n",
    "def plot_corr_heatmap(data_csv: str, out_path: str, top_n: int = 30):\n",
    "    if not os.path.exists(data_csv):\n",
    "        print(f\"[WARN] Dataset not found: {data_csv}\")\n",
    "        return\n",
    "    df = pd.read_csv(data_csv)\n",
    "    # Only numeric columns\n",
    "    num_df = df.select_dtypes(include=[np.number]).copy()\n",
    "    if num_df.shape[1] < 2:\n",
    "        print(\"[WARN] Not enough numeric columns for correlation heatmap.\")\n",
    "        return\n",
    "    # If too many columns, take the ones with highest variance (top_n)\n",
    "    if num_df.shape[1] > top_n:\n",
    "        variances = num_df.var().sort_values(ascending=False)\n",
    "        cols = variances.head(top_n).index.tolist()\n",
    "        num_df = num_df[cols]\n",
    "    corr = num_df.corr(numeric_only=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if _HAS_SEABORN:\n",
    "        sns.heatmap(corr, cmap=\"viridis\", annot=False, square=True, cbar=True)\n",
    "    else:\n",
    "        # fallback with matplotlib imshow\n",
    "        im = plt.imshow(corr.values, cmap=\"viridis\", aspect=\"equal\")\n",
    "        plt.colorbar(im)\n",
    "        plt.xticks(range(corr.shape[1]), corr.columns, rotation=90)\n",
    "        plt.yticks(range(corr.shape[0]), corr.index)\n",
    "    plt.title(\"Correlation Heatmap (Numeric Features)\")\n",
    "    plt.tight_layout()\n",
    "    _ensure_dir(out_path)\n",
    "    plt.savefig(out_path, dpi=180)\n",
    "    plt.close()\n",
    "    print(f\"[OK] Saved correlation heatmap -> {out_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Error Heatmap by Area × Year (if available)\n",
    "# ----------------------------\n",
    "def plot_error_pivot_heatmap(preprocess_pkl: str, model_h5: str, data_csv: str, out_path: str,\n",
    "                             area_cols=(\"Area\",\"area\",\"Country\",\"country\"),\n",
    "                             year_cols=(\"Year\",\"year\")):\n",
    "    if not (os.path.exists(preprocess_pkl) and os.path.exists(model_h5) and os.path.exists(data_csv)):\n",
    "        print(\"[WARN] Missing one of preprocess/model/data files; skipping error pivot heatmap.\")\n",
    "        return\n",
    "    bundle = joblib.load(preprocess_pkl)\n",
    "    pre = bundle[\"preprocess\"]\n",
    "    df = pd.read_csv(data_csv)\n",
    "    target = bundle.get(\"target_col\", None) or _detect_target(df)\n",
    "    df = df.dropna(subset=[target]).copy()\n",
    "\n",
    "    # Find area/year columns\n",
    "    area_col = next((c for c in area_cols if c in df.columns), None)\n",
    "    year_col = next((c for c in year_cols if c in df.columns), None)\n",
    "    if area_col is None or year_col is None:\n",
    "        print(\"[WARN] Area/Year columns not found; skipping Area×Year error heatmap.\")\n",
    "        return\n",
    "\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target].astype(float).values\n",
    "    Xp = pre.transform(X)\n",
    "\n",
    "    # IMPORTANT: disable compile on load to avoid 'mse' lookup error\n",
    "    model = keras.models.load_model(model_h5, compile=False)\n",
    "    yhat = model.predict(_to_numpy(Xp), verbose=0).ravel()\n",
    "    abs_err = np.abs(yhat - y)\n",
    "\n",
    "    tmp = pd.DataFrame({\n",
    "        \"area\": df[area_col].astype(str).values,\n",
    "        \"year\": df[year_col].values,\n",
    "        \"mae\": abs_err\n",
    "    })\n",
    "    pivot = tmp.groupby([\"area\",\"year\"])[\"mae\"].mean().reset_index()\n",
    "    pivot_tbl = pivot.pivot(index=\"area\", columns=\"year\", values=\"mae\").fillna(np.nan)\n",
    "\n",
    "    plt.figure(figsize=(12, max(6, 0.25 * len(pivot_tbl))))\n",
    "    if _HAS_SEABORN:\n",
    "        sns.heatmap(pivot_tbl, cmap=\"magma\", cbar=True)\n",
    "    else:\n",
    "        im = plt.imshow(pivot_tbl.values, cmap=\"magma\", aspect=\"auto\")\n",
    "        plt.colorbar(im)\n",
    "        plt.yticks(range(pivot_tbl.shape[0]), pivot_tbl.index)\n",
    "        plt.xticks(range(pivot_tbl.shape[1]), pivot_tbl.columns, rotation=90)\n",
    "    plt.title(\"Mean Absolute Error by Area × Year\")\n",
    "    plt.xlabel(\"Year\"); plt.ylabel(\"Area\")\n",
    "    plt.tight_layout()\n",
    "    _ensure_dir(out_path)\n",
    "    plt.savefig(out_path, dpi=180)\n",
    "    plt.close()\n",
    "    print(f\"[OK] Saved error pivot heatmap -> {out_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Run all plots\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) training curves\n",
    "    plot_training_curves(HISTCSV, os.path.join(BASE_DIR, \"loss_mae.png\"))\n",
    "\n",
    "    # 2) pred vs actual hexbin\n",
    "    plot_pred_vs_actual_hex(\n",
    "        preprocess_pkl=PKL_PATH,\n",
    "        model_h5=H5_PATH,\n",
    "        data_csv=DATACSV,\n",
    "        out_path=os.path.join(BASE_DIR, \"pred_vs_actual_hex.png\")\n",
    "    )\n",
    "\n",
    "    # 3) correlation heatmap\n",
    "    plot_corr_heatmap(\n",
    "        data_csv=DATACSV,\n",
    "        out_path=os.path.join(BASE_DIR, \"corr_heatmap.png\"),\n",
    "        top_n=30\n",
    "    )\n",
    "\n",
    "    # 4) error pivot heatmap (Area × Year)\n",
    "    plot_error_pivot_heatmap(\n",
    "        preprocess_pkl=PKL_PATH,\n",
    "        model_h5=H5_PATH,\n",
    "        data_csv=DATACSV,\n",
    "        out_path=os.path.join(BASE_DIR, \"error_heatmap.png\")\n",
    "    )\n",
    "\n",
    "    print(\"[DONE] Plots saved in:\", BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf6457-6f6b-45d4-9e3c-cadf2f7d75f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
